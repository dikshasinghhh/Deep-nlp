{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12572454,"sourceType":"datasetVersion","datasetId":7939738}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install dependencies (run only once)\n!pip install -q transformers torchaudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:17:22.986067Z","iopub.execute_input":"2025-07-28T11:17:22.986744Z","iopub.status.idle":"2025-07-28T11:18:34.614342Z","shell.execute_reply.started":"2025-07-28T11:17:22.986718Z","shell.execute_reply":"2025-07-28T11:18:34.613521Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Import, device set, model & processor load\n\nimport torch\nfrom transformers import SeamlessM4Tv2ForSpeechToText, AutoProcessor\nimport torchaudio\n\n# Set device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# Load processor and model\nmodel_id = \"facebook/seamless-m4t-v2-large\"\nprocessor = AutoProcessor.from_pretrained(model_id)\nmodel = SeamlessM4Tv2ForSpeechToText.from_pretrained(model_id).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:19:03.886494Z","iopub.execute_input":"2025-07-28T11:19:03.886780Z","iopub.status.idle":"2025-07-28T11:21:04.912890Z","shell.execute_reply.started":"2025-07-28T11:19:03.886757Z","shell.execute_reply":"2025-07-28T11:21:04.912126Z"}},"outputs":[{"name":"stderr","text":"2025-07-28 11:19:18.784242: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753701558.933353      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753701558.976222      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6c52fe46a744485965e9f4615603a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992ff554e37c4f74b43751fcb2e9493a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.17M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f37a56776b3d4523901d838ec3f7fb72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e57998f71d144db5b0055bf32a438fdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e253664f2eda44d2bd8350bacacdf441"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ce307631ed4b60b4d80ac1cc99d59e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57b82fae4c4b4ac282dfe3ecd57ee91f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33670a09159f46d2a7f8f85a7411cb2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f9dd061111a409bbba7974bf97621ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65ea00f0b19e402f9643ddfd9d66b885"}},"metadata":{}},{"name":"stderr","text":"Instantiating a decoder SeamlessM4Tv2Attention without passing `layer_idx` is not recommended and will lead to errors during the forward call, if caching is used. Please make sure to provide a `layer_idx` when creating this class.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcb94b5b3e3e4347a52ea792edb79bd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc8f7c02e1a428aa46f9b6581ddf26a"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Define the translation function\ndef translate_speech_to_english(audio_file):\n    # Load and resample\n    speech_array, sampling_rate = torchaudio.load(audio_file)\n    if sampling_rate != 16000:\n        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n        speech_array = resampler(speech_array)\n    speech_array = speech_array.squeeze().numpy()\n\n    # Preprocess\n    inputs = processor(audios=speech_array, sampling_rate=16000, return_tensors=\"pt\")\n\n    # Move to device\n    for k in inputs:\n        inputs[k] = inputs[k].to(device)\n\n    # Generate translation directly\n    translated_tokens = model.generate(**inputs, tgt_lang=\"eng\")\n\n    # Decode\n    translated_text = processor.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n    return translated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:21:09.732216Z","iopub.execute_input":"2025-07-28T11:21:09.732863Z","iopub.status.idle":"2025-07-28T11:21:09.738736Z","shell.execute_reply.started":"2025-07-28T11:21:09.732840Z","shell.execute_reply":"2025-07-28T11:21:09.737985Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Cell 4: Provide audio file path and run inference\naudio_path = \"/kaggle/input/audio-files/14765312647 14765312640/cv-corpus-21.0-delta-2025-03-14/hi/clips/common_voice_hi_41938751.mp3\"\n\ntranslated_text = translate_speech_to_english(audio_path)\nprint(f\"\\nTranslated Text:\\n{translated_text}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:21:32.264625Z","iopub.execute_input":"2025-07-28T11:21:32.264903Z","iopub.status.idle":"2025-07-28T11:21:32.905678Z","shell.execute_reply.started":"2025-07-28T11:21:32.264884Z","shell.execute_reply":"2025-07-28T11:21:32.904837Z"}},"outputs":[{"name":"stdout","text":"\nTranslated Text:\nKashmir: The world of fear and anger\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\n\n# Create a dictionary with the translation\noutput_data = {\n    \"audio_file\": audio_path,\n    \"translated_text\": translated_text\n}\n\n# Define output path\noutput_json_path = \"translated_output.json\"\n\n# Save to JSON file\nwith open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(output_data, f, ensure_ascii=False, indent=4)\n\nprint(f\"\\nâœ… Translated text saved to {output_json_path}\")\nimport shutil\n\n# Move file to the output directory\nshutil.move(output_json_path, f\"/kaggle/working/{output_json_path}\")\n\nprint(f\"\\nğŸ“ You can find the JSON file in the 'working' directory of kaggle.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:21:40.581391Z","iopub.execute_input":"2025-07-28T11:21:40.582106Z","iopub.status.idle":"2025-07-28T11:21:40.587859Z","shell.execute_reply.started":"2025-07-28T11:21:40.582056Z","shell.execute_reply":"2025-07-28T11:21:40.587240Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Translated text saved to translated_output.json\n\nğŸ“ You can find the JSON file in the 'working' directory of kaggle.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip install SpeechRecognition pydub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:22:31.822315Z","iopub.execute_input":"2025-07-28T11:22:31.822606Z","iopub.status.idle":"2025-07-28T11:22:36.109493Z","shell.execute_reply.started":"2025-07-28T11:22:31.822586Z","shell.execute_reply":"2025-07-28T11:22:36.108647Z"}},"outputs":[{"name":"stdout","text":"Collecting SpeechRecognition\n  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.0)\nDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: SpeechRecognition\nSuccessfully installed SpeechRecognition-3.14.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"pip install indic-transliteration","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:22:36.110782Z","iopub.execute_input":"2025-07-28T11:22:36.111028Z","iopub.status.idle":"2025-07-28T11:22:39.685901Z","shell.execute_reply.started":"2025-07-28T11:22:36.111006Z","shell.execute_reply":"2025-07-28T11:22:39.684930Z"}},"outputs":[{"name":"stdout","text":"Collecting indic-transliteration\n  Downloading indic_transliteration-2.3.69-py3-none-any.whl.metadata (1.4 kB)\nCollecting backports.functools-lru-cache (from indic-transliteration)\n  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (2024.11.6)\nRequirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (0.16.0)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (0.10.2)\nCollecting roman (from indic-transliteration)\n  Downloading roman-5.1-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (8.2.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (4.14.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (14.0.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\nDownloading indic_transliteration-2.3.69-py3-none-any.whl (155 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\nDownloading roman-5.1-py3-none-any.whl (5.8 kB)\nInstalling collected packages: roman, backports.functools-lru-cache, indic-transliteration\nSuccessfully installed backports.functools-lru-cache-2.0.0 indic-transliteration-2.3.69 roman-5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import speech_recognition as sr\nfrom pydub import AudioSegment\nfrom indic_transliteration.sanscript import transliterate, DEVANAGARI, ITRANS\nimport re\n\ndef convert_audio_to_wav(audio_path):\n    if audio_path.lower().endswith('.wav'):\n        return audio_path\n\n    sound = AudioSegment.from_file(audio_path)\n    wav_path = \"converted_audio.wav\"\n    sound.export(wav_path, format=\"wav\")\n    return wav_path\n\ndef transcribe_audio_to_hindi(audio_path):\n    recognizer = sr.Recognizer()\n    try:\n        wav_path = convert_audio_to_wav(audio_path)\n        with sr.AudioFile(wav_path) as source:\n            audio_data = recognizer.record(source)\n        return recognizer.recognize_google(audio_data, language='hi-IN')\n    except sr.UnknownValueError:\n        return \"Could not understand the audio.\"\n    except sr.RequestError as e:\n        return f\"Could not request results; {e}\"\n    except Exception as e:\n        return f\"Error: {e}\"\n\ndef clean_hinglish_text(raw_text):\n    # Basic replacements for casual readability\n    substitutions = {\n        'aa': 'a',     # simplify long vowels\n        'ii': 'i',\n        'ee': 'i',\n        'uu': 'u',\n        'oo': 'u',\n        'kh': 'kh',\n        'gh': 'gh',\n        'chh': 'chh',\n        'jh': 'jh',\n        'ph': 'f',\n        'bh': 'bh',\n        'sh': 'sh',\n        'á¹£': 'sh',\n        'á¹›': 'r',\n        'á¹­': 't',\n        'á¸': 'd',\n        'Ã±': 'n',\n        'á¹…': 'n',\n    }\n\n    # Lowercase and remove non-alpha characters\n    text = raw_text.lower()\n    for k, v in substitutions.items():\n        text = text.replace(k, v)\n\n    # Optional: remove duplicate vowels/consonants if needed\n    text = re.sub(r'\\s+', ' ', text)  # normalize spaces\n    return text\n\ndef transliterate_to_casual_hinglish(hindi_text):\n    try:\n        raw = transliterate(hindi_text, DEVANAGARI, ITRANS)\n        cleaned = clean_hinglish_text(raw)\n        return cleaned\n    except Exception as e:\n        return f\"Transliteration Error: {e}\"\n\nif __name__ == \"__main__\":\n    audio_file = input(\"Enter path to your audio file: \")\n    hindi_text = transcribe_audio_to_hindi(audio_file)\n    print(\"\\nHindi (Devanagari):\", hindi_text)\n\n    if \"Error\" not in hindi_text and \"Could not\" not in hindi_text:\n        hinglish = transliterate_to_casual_hinglish(hindi_text)\n        print(\"\\nTranslated Text:\", hinglish)\n    else:\n        print(\"\\nNo valid transcription to transliterate.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T11:26:02.143167Z","iopub.execute_input":"2025-07-28T11:26:02.143756Z","iopub.status.idle":"2025-07-28T11:26:05.345574Z","shell.execute_reply.started":"2025-07-28T11:26:02.143736Z","shell.execute_reply":"2025-07-28T11:26:05.344790Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter path to your audio file:  /kaggle/input/audio-files/14765312647 14765312640/cv-corpus-21.0-delta-2025-03-14/hi/clips/common_voice_hi_41938750.mp3\n"},{"name":"stdout","text":"\nHindi (Devanagari): à¤ªà¤¾à¤•à¤¿à¤¸à¥à¤¤à¤¾à¤¨à¥€ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¤ªà¤¤à¤¿ à¤ªà¤°à¤µà¥‡à¤œ à¤®à¥à¤¶à¤°à¥à¤°à¤« à¤¨à¥‡ à¤…à¤ªà¤¨à¥‡ à¤ªà¤¦ à¤¸à¥‡ à¤‡à¤¸à¥à¤¤à¥€à¤«à¤¾ à¤¦à¤¿à¤¯à¤¾\n\nTranslated Text: pakistani rashtrapati paraveja musharrafa ne apane pada se istifa diya\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}